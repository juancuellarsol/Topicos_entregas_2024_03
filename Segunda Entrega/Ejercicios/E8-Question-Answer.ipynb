{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sergiomora03/AdvancedTopicsAnalytics/blob/main/exercises/E7-QuestionAnswer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2NseOxJAIFM"
      },
      "source": [
        "## Question & Answer\n",
        "\n",
        "Creating a Question-Answer Transformer model or QA Transformer can be beneficial for several reasons, particularly in the field of Natural Language Processing (NLP). Here are some compelling reasons why you might want to develop a QA Transformer:\n",
        "\n",
        "1. **Question-Answering Systems:** QA Transformers are designed to provide accurate and contextually relevant answers to questions posed in natural language. These systems have a wide range of practical applications, including chatbots, virtual assistants, customer support, and information retrieval.\n",
        "\n",
        "2. **Information Retrieval:** QA Transformers can be used to search through large corpora of text and extract precise answers to user queries. This can improve the efficiency and effectiveness of information retrieval systems.\n",
        "\n",
        "3. **Document Summarization:** QA Transformers can be used to summarize long documents by answering questions about the document's content. This makes it easier for users to quickly understand the key points and relevant information in a text.\n",
        "\n",
        "4. **Education and E-Learning:** QA Transformers can be integrated into educational platforms to provide instant answers and explanations to students' questions. They can also help with the automatic generation of quiz questions and answers.\n",
        "\n",
        "5. **Content Generation:** QA Transformers can assist in content generation by automatically answering questions based on available knowledge. This can be useful for generating FAQs, product descriptions, and informative articles.\n",
        "\n",
        "6. **Customer Support:** Many companies use QA systems to automate responses to frequently asked questions, freeing up human agents to handle more complex queries and providing customers with quick solutions.\n",
        "\n",
        "7. **Medical Diagnosis:** QA Transformers can assist medical professionals by answering questions related to patient records, medical literature, and diagnostic information, potentially leading to faster and more accurate diagnoses.\n",
        "\n",
        "8. **Legal and Compliance:** In the legal field, QA Transformers can be used to search and extract information from legal documents, assisting lawyers in their research and case preparation.\n",
        "\n",
        "9. **Language Translation:** QA Transformers can be used to answer questions about language translation, helping users understand the meaning of words, phrases, or sentences in different languages.\n",
        "\n",
        "10. **Scientific Research:** QA Transformers can support researchers by answering questions related to scientific literature, allowing them to quickly access relevant information for their studies.\n",
        "\n",
        "11. **Decision Support:** QA Transformers can aid in decision-making processes by providing answers to questions related to data analysis, market research, and business intelligence.\n",
        "\n",
        "12. **Accessibility:** QA Transformers can improve accessibility for individuals with disabilities by providing spoken or written answers to their questions, helping them access information more easily.\n",
        "\n",
        "Overall, QA Transformers have the potential to enhance information retrieval, automation, and user interaction in various domains, making them a valuable tool in the development of intelligent systems and applications. The ability to provide accurate and context-aware answers to questions in natural language is a key advantage of these models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0voj5DTPAukU"
      },
      "source": [
        "---\n",
        "Exercise:\n",
        "\n",
        "Now, as a data scientist expert in NLP, you are asked to create a model to be able to answer question in Spanish. Your stakeholders will pass you an article and one question and your model should answer it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bw-K8uOkAG95",
        "outputId": "9da1870c-45aa-4d54-cddf-4e4632507546"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: requests in /Users/juanpablo.cuellar/Library/Python/3.9/lib/python/site-packages (2.32.3)\n",
            "Collecting beautifulsoup4\n",
            "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 2.2 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /Users/juanpablo.cuellar/Library/Python/3.9/lib/python/site-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/juanpablo.cuellar/Library/Python/3.9/lib/python/site-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/juanpablo.cuellar/Library/Python/3.9/lib/python/site-packages (from requests) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/juanpablo.cuellar/Library/Python/3.9/lib/python/site-packages (from requests) (2.2.2)\n",
            "Collecting soupsieve>1.2\n",
            "  Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
            "Installing collected packages: soupsieve, beautifulsoup4\n",
            "Successfully installed beautifulsoup4-4.12.3 soupsieve-2.6\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.2 is available.\n",
            "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install requests beautifulsoup4 transformers torch ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/juanpablo.cuellar/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from transformers import pipeline\n",
        "from langdetect import detect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hKs-JhtBwzf",
        "outputId": "325593e2-4ee2-4996-d97d-5d37c4441e38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Over the course of February, Geoffrey Hinton, one of the most influential AI researchers of the past 50 years, had a “slow eureka moment.”\n",
            "Hinton, 76, has spent his career trying to build AI systems that model the human brain, mostly in academia before joining Google in 2013. He had always believed that the brain was better than the machines that he and others were building, and that by making them more like the brain, they would improve. But in February, he realized “the digital intelligence we’ve got now may be better than the brain already. It’s just not scaled up quite as big.” \n",
            "Developers around the world are currently racing to build the biggest AI systems that they can. Given the current rate at which AI companies are increasing the size of models, it could be less than five years until AI systems have 100 trillion connections—roughly as many as there are between neurons in the human brain.\n",
            "Alarmed, Hinton left his post as VP and engineering fellow in May and gave a flurry of interviews in which he explained that he had left in order to be able to speak freely on the dangers of AI—and his regrets over helping bring that technology into existence. He worries about what could happen once AI systems are scaled up to the size of human brains—and the prospect of humanity being wiped out by the technology he helped create. “This stuff will get smarter than us and take over,” says Hinton. “And if you want to know what that feels like, ask a chicken.”\n",
            "Born and raised in England, Hinton comes from a long line of luminaries, with relatives including the mathematician Mary Everest Boole and logician George Boole, whose work is crucial to modern computer science; surgeon James Hinton; and surveyor George Everest, who gave his name to the mountain. \n",
            "The human brain always fascinated Hinton. As a Cambridge University undergraduate, he tried a range of subjects—physiology, physics, philosophy—before graduating with a degree in experimental psychology in 1970. He worked briefly as a carpenter before starting a Ph.D. in AI at the University of Edinburgh, then the U.K.’s only postgraduate program on the subject, in 1972.\n",
            "In the 1970s, artificial intelligence, after failing to live up to its postwar promise, was going through a period of dampened enthusiasm now referred to as the “AI winter.” In this unfashionable field, Hinton pursued an unpopular idea: AI systems known as neural networks, which mimicked the structure of the human brain. His thesis adviser urged him on a weekly basis to change his approach. Each time he replied, “Give me another six months and I’ll prove to you that it works.”\n",
            "Upon completion of his Ph.D., Hinton moved to the U.S., where more funding was available for his research. He published pathbreaking research, for which he was awarded the 2018 Turing Award, in posts at universities across the U.S., before eventually taking a professorship in computer science at the University of Toronto. Toronto has become Hinton’s home base; he travels relatively infrequently because back problems prevent him from sitting down. During car journeys he lies across the back seat; he eats kneeling before a table “like a monk at the altar”; and as he spoke to TIME he swayed gently in front of a head-height camera.\n",
            "In 2012, Hinton and two of his graduate students, Alex Krizhevsky and Ilya Sutskever, now chief scientist at OpenAI, entered ImageNet, a once annual competition in which researchers competed to build the most accurate image-recognition AI systems. They dominated the competition—an emphatic demonstration that neural networks had come of age. Hinton’s persistence had paid off.\n",
            "He and his two students began receiving lucrative offers from big tech companies. They set up a shell company called DNN-research to auction their expertise, and four tech firms—Google, Microsoft, Baidu, and DeepMind—bid tens of millions for the company. After a week, Hinton chose Google over the final bidder, Baidu. In 2013, he joined Google Brain, the cutting-edge machine-learning team he left in May.\n",
            "Hinton has been instrumental in the development and popularization of neural networks, the dominant AI development paradigm that has allowed huge amounts of data to be ingested and processed, leading to advances in image recognition, language understanding, and self-driving cars. His work has potentially hastened the future he fears, in which AI becomes superhuman with disastrous results for humans. In an interview with the New York Times, Hinton said, “I console myself with the normal excuse: If I hadn’t done it, somebody else would have.”\n",
            "Hinton does not know how to prevent superhuman AI systems from taking over. If there’s any hope, he says, it lies with the next generation, noting that he feels too old to continue contributing to research. Many scientists switch to policy work later in their careers, but he declined Google’s offer to take such a role at the company. “I’ve never been very good at or interested in policy issues,” he tells TIME. “I’m a scientist.” \n",
            "Instead, Hinton has spent the past few months sounding the alarm—he can explain the technical details of AI in an accessible way as well as anyone and spends much of his time giving interviews to raise public awareness. He has also spoken with policymakers, including officials in the U.K. Prime Minister’s office, Canadian Prime Minister Justin Trudeau, Executive Vice-President of the European Commission Margrethe Vestager, and U.S. Senators Bernie Sanders and Jon Ossoff.\n",
            "While on a theoretical level he now grasps the risks from AI, Hinton says that his emotions haven’t yet caught up. “The idea that we’re going to be replaced as the apex intelligence is just very hard to get your head around.” \n",
            "But for now, he takes his cues from another relative: his cousin Joan Hinton was one of the only women scientists to work on the Manhattan Project. After the nuclear weapons that she helped to create were dropped on Hiroshima and Nagasaki, she became a peace activist. In 1948 she moved to China, and she spent most of the rest of her life working on dairy farms as an ardent Maoist. Hinton’s own retirement plans are less strident but likewise bucolic: he intends to rediscover carpentry and take long walks.\n",
            "Write to Will Henshall at will.henshall@time.com.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# URL del artículo\n",
        "url = \"https://time.com/collection/time100-ai/6309026/geoffrey-hinton/\"\n",
        "\n",
        "# Realizar una solicitud HTTP para obtener el contenido de la página\n",
        "response = requests.get(url)\n",
        "\n",
        "# Verificar si la solicitud fue exitosa\n",
        "if response.status_code == 200:\n",
        "    # Analizar el contenido HTML de la página con BeautifulSoup\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "    # Encontrar el contenido del artículo (puedes inspeccionar el HTML de la página para encontrar la estructura adecuada)\n",
        "    article_content = soup.find(\"div\", {\"class\": \"article-content\"})\n",
        "\n",
        "    # Extraer el texto del artículo\n",
        "    article_text = \"\"\n",
        "    for paragraph in article_content.find_all(\"p\"):\n",
        "        article_text += paragraph.get_text() + \"\\n\"\n",
        "\n",
        "    # Imprimir el texto del artículo\n",
        "    print(article_text)\n",
        "else:\n",
        "    print(\"Error al obtener la página:\", response.status_code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "StIrHeBAB07H"
      },
      "outputs": [],
      "source": [
        "question = \"How is Geoffrey Hinton?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'score': 0.5176942348480225, 'start': 46, 'end': 109, 'answer': 'one of the most influential AI researchers of the past 50 years'}\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "reader = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\", tokenizer=\"distilbert-base-cased\")\n",
        "question = \"Who is Geoffrey Hinton?\"\n",
        "outputs = reader(question=question, context=article_text)\n",
        "print(outputs)\n",
        "     \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Creación de modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extraer información de un articulo en español"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A inicios de marzo, TIME se sentó con la sensación musical mundial Benito Antonio Martínez Ocasio, también conocido como Bad Bunny, mientras se preparaba para actuar en Coachella, el primer artista latino en encabezar el destacado festival de música. Durante una amplia entrevista, Martínez Ocasio habló con franqueza sobre su vida, su música y cómo pasa más tiempo en estos días en Los Ángeles, un lugar al que “siempre soñó ir” cuando era un chamaquito (un niño pequeño) mientras crecía. Puerto Rico. También se refirió a su floreciente carrera como actor, junto con la responsabilidad que siente como reguetonero a quien a menudo se le pide que hable en nombre de toda una región.\n",
            "La siguiente transcripción ha sido condensada y editada para mayor claridad. Para la versión en inglés haga clic aquí.\n",
            " Realmente, sí me gusta. Siempre me ha gustado desde que he estado viniendo unos años. Es un lugar al que desde que era chamaquito—antes de todo esto—siempre soñé con ir. Siempre soñé con ir algún día a Los Ángeles porque era fanático de los Lakers y Kobe.\n",
            "Coño. Si no tuviera familia en los Estados Unidos, no sería latino.\n",
            "Recuerdo la primera vez que vine a los Estados Unidos. Tenía 12 años. Era verano y fui a Connecticut, Rhode Island, Pensilvania. Estuve en casas de diferentes familiares, pero visité Nueva York solo un día, fuimos y volvimos. Lo recuerdo muy bien. Esa fue la primera vez. Y fue la primera y única vez, hasta que crecí.\n",
            "Read the Cover Story: Bad Bunny’s Next Move\n",
            "[Risas audibles] Ya sabes la respuesta a eso. Puerto Rico, definitivamente 1000 veces. Todavía no me he metido en el agua. Voy a ver si en verano el agua se calienta y luego voy.\n",
            "Siempre digo que tuve una vida muy normal. Crecí con mi mamá y mi papá. Soy el hermano mayor de tres, así que recuerdo haber esperado a mis hermanos. Cuando vino mi primer hermano, Bernie y el segundo, Misael. Mi madre era maestra y mi padre era camionero. Así que sabes que éramos gente trabajadora. Muy católico, nosotros fuimos a la iglesia. Teníamos que hacerlo bien en la escuela. Crecí con mucho amor de mi madre y mi padre. Los vi a veces esforzándose, pasando por momentos difíciles para traernos comida y otros momentos fáciles. Fueron momentos hermosos, a veces de incertidumbre, pero al final siempre agradecido con el núcleo en el que crecí; mi familia, mi barrio, mi pueblo y la forma en que crecí, porque de ahí, adquirí mucha experiencia y muchos conocimientos que me hacen ser la persona que soy hoy.\n",
            "Lo que más he hecho en la vida es escuchar música. Desde pequeño siempre fui fanático de la música. Yo de niño tenía muchos CDs de salsa, merengue. Mi mamá escuchaba mucho merengue y balada, y mi papá escuchaba salsa. Cuando era ‘chamaquito’ o niño, escuchaba rap y reggaeton. Siempre recuerdo cuando tenía 5 años, para Navidad me regalaron un CD de Vico-C, “Aquel Que Había Muerto,” con la carátula oscura, casi negra, apenas se veía la cara de Vico C. Mi mamá compraba discos de un catálogo, que era como un libro y tú elegías los discos y venían por docenas, bueno, ella elegía como ocho y me dejaba elegir los últimos cuatro. Tomaría CDs de Marc Anthony, Victor Manuel y CDs de música de bolero. Crecí siempre escuchando música y trataba de imitar las voces de los cantantes y los sonidos que hacían. Desde pequeño siempre fue mi pasión. Siempre fui un gran fan de los artistas. Por eso cuando me preguntan ‘¿Qué artista te inspiró?’ Nunca digo uno solo porque escuché tantos artistas y géneros como el reggaetón, que tiene muchos artistas que me inspiraron, y la salsa. Diría que todo el movimiento de la música latina me inspiró. \n",
            "No creo que lo sepan. [Risas] En realidad, mi papá está orgulloso de mí y está feliz de que me siento bien y de que estoy viviendo mis sueños. Siempre agradezco a Dios que yo, mis amigos y mi familia, mantengamos los pies en la tierra. Voy a la casa de mi papá y me siento tan relajado. Muy normal. Como si no pasara nada. Fuera de esa casa quizás el mundo esté escuchando y hablando de mí, pero en esa casa todo es igual. Nada ha cambiado. Mi papá no actúa de una manera nueva ni me trata de una manera nueva. Para mí es hermoso que me guste ir allí y todavía me miran con ojos de ‘Ven aquí, Benito Antonio. El bebé. Su hijo.’ ¿Tú entiendes? Mi mamá es igual que mi papá. Por eso digo que no saben pero no en el sentido de que no lo entiendan, es en el sentido de que sigo siendo la misma persona y nada ha cambiado en cómo nos sentimos y nos tratamos. Cada vez que voy a la casa me siento así…un hogar.\n",
            "Read More: The 10 Best Albums of 2022\n",
            "Quizás al principio no hubiera imaginado esto que soñé con esto. Cuando estaba solo en mi habitación haciendo ritmos, soñando que algún día tendría éxito en la música, no. Pero ahora, con el paso del tiempo y he visto grandes cosas, ahora puedo imaginar lo siguiente y lo siguiente. Recuerdo que hace dos años me decía ‘papi’ ya estoy en un nivel que si bajo no voy a ser el mismo de antes, no voy a poder recuperar mi vida normal por así decirlo. Pero sí, me lo he imaginado, pero si me preguntas desde el principio cuando era chamaquito, no. Cuando era pequeño, solo soñaba con la música y que alguien escuchara mi música, siempre digo eso. Si me escucharan mil personas y yo actuara una vez al mes en un lugarcito, solo con eso sería feliz. Pero el hambre y la pasión que tengo por esto es imposible porque siempre quiero dar más y más y más. \n",
            "Obvio que sí, y sobre esto te puedo decir, por encima de otras personas, que si no fuera por las redes sociales no estaría aquí. Lo que no creo es que sea una ventaja. Hay un montón de artistas del pasado que dicen, ‘Durante mi tiempo no había Spotify. Durante mi tiempo no había Instagram.’ Pero había otras cosas. Por ejemplo, fue más difícil obtener exposición para llegar a la posición. Pero al mismo tiempo fue mejor para aquellos que lo lograron. Ahora estamos en un momento en el que en cualquier momento puedes lanzar una canción. Ahora compito con un millón de personas. Cuando salgo con algo ese mismo día salen mil artistas con canciones. Veinte álbumes saliendo en la misma noche. Antes no, salían uno, dos o tres discos. No había tanta saturación en la música. Sacó un disco ahora y pasa una semana y han llegado 15 discos nuevos. Entonces es más fácil que más personas dejen de escuchar mi álbum y comiencen a escuchar otro. Antes, si comprabas un álbum a $15, no tendrías dinero para comprar otro álbum. Te lo ibas a quemar y ‘pela, pela, pela.’ Hoy no, escuchas mi disco y te aburres, puedes escuchar otros. Así que mantenerte ahí en la posición de que te sigan escuchando, mantenerte en la posición de que tu álbum siga ‘top,’ es mucho más difícil que antes. Hoy en día es mucho más difícil. Antes escuchabas la misma canción un año entera en la emisora. Es la emisora que pone tu canción y si no les gusta, sí tienes chavos (dinero) para pagar la emisora, sino no podrías competir con nadie. Ahora cualquiera pone una canción en los medios y puede ‘pegarla.’\n",
            "No. Cuando estoy en el estudio disfruto lo que hago. No estoy pensando en la cantidad de gente que está grabando o no. Yo hago música como si fuera la única persona en el mundo.\n",
            "Siempre digo que no, pero creo que miento, porque al final del día soy muy competitivo, pero con todo. Si estoy jugando al ajedrez, quiero ganar. Si estoy haciendo chistes, quiero contar mejores chistes. Soy muy competitivo. En todas las situaciones. Así que obviamente en la música lo soy. Pero en el buen sentido. Pero no me gusta ver a otros perder. Me gusta que todos ganen. Hay espacio para todos nosotros. Me gusta ver a los demás triunfar y tener éxito. Me gusta ver que la gente tenga buena música porque me hará sentir mejor. Si veo a alguien haciendo una canción que está rompiendo, si hay una canción cabrona, yo voy hacer una canción más cabrona. Quiero hacer algo mejor. Pero no para opacarlo a él, sino porque quiero hacer algo mejor. Podemos brillar todos en el mundo. \n",
            "No sé. La forma en que hago música es de una manera tan real. Le doy tanto amor a la música. Siempre digo que mi mamá me dio tanto amor desde ‘chiquito,’ por eso tengo tanto que dar al mundo y a los demás. Creo que mis canciones son las mismas. Le doy tanto amor a mis canciones que no se acaba. Esa energía cada vez que escuches mi canción te dará mucha alegría. No hago canciones solo por tirarlas. Cuando tenga una canción para tirar, entonces se tira.\n",
            "¿Ahora mismo? Sí. [Alcanza el teléfono en el bolsillo derecho] Pero no te lo voy a enseñar. [Risas]\n",
            "Read More: ‘I Make Music Like I’m the Only Person in the World.’ Bad Bunny on Coachella, Hollywood, and Topping Himself\n",
            "Hago música para la gente que me quiere. Cuando leo comentarios que dicen: ‘Bad Bunny, ahora no voy a escuchar tu música’, está bien. Si ya no quieres escuchar mi música, está bien. Eso está bien, a alguien le gustará. Hago música para quien quiera escucharme y para quien quiera conectar conmigo. Si no te gusta lo que estoy haciendo, no voy a hacer otra cosa para que a ti te guste. Si no te gusta, pues ‘brother,’ hay muchos artistas por ahí, y tal vez encuentres a alguien que te guste. A alguien le va a gustar lo que estoy haciendo y esas son las personas a las que les estoy cantando. Pero obviamente, sí hago música para Puerto Rico. Es donde nací y crecí. Soy fan de nuestra gente, de nuestra cultura, de nuestra cultura también dentro del reggaetón. Cuando escribo y hago música mi espíritu siempre está en Puerto Rico y trato de que la música que hago sea del agrado de la gente de allá.\n",
            "Muchos artistas hacen canciones, se tiran una foto, la portada y ya, luego el video y ya está. Quiero crear todo un mundo, un ambiente y un sentimiento entero alrededor de un álbum, desde los videos, las visuales, la portada, la temática, todo sincronizado, con el propósito de que lo escuches para con el propósito de que lo escuches para que te puedas sentir en algún lugar o sentir de alguna manera. Si alguien está en la f-king Suiza, puede sentir que está en el Caribe, puede sentir que está en la playa. Es por eso que todas las imágenes de las canciones son mías en la playa y son 360, así que si te pones los [auriculares de realidad virtual], estarás en la playa conmigo. Si estás en Puerto Rico, aún mejor porque entonces no necesitas los [VR]: estás allí. \n",
            "He sido fan suyo desde siempre. He tenido sueños desde que era chamaquito para trabajar un día con Tainy. Incluso después de que entró en la música, me tomó tiempo poder trabajar con él. Recuerdo cuando hice mi primer disco y me preguntaron, ‘¿Con quién quieres trabajar?’ Y dije: ‘Quiero trabajar con Tainy’. Y hasta el sol de hoy seguimos trabajando. No trabajo con muchos productores así de mano a mano.\n",
            "Read More: The Best Latin Songs and Albums of 2022\n",
            "Siempre trato de dar lo más real de mi en mis canciones. Yo soy un chamaquito. [Risas] Y tenemos distintas preocupaciones y deseos de hacer una cosa un día y al día siguiente no. Hoy a lo mejor quiero ir a la discoteca a beber y fumar, y mañana quiero estar tranquilo en mi casa viendo una película. El martes quiero hacer ejercicio y el miércoles quiero comer una hamburguesa. Y luego estaré pensando en mi ex o en una chica que me gusta. Y luego mañana estoy molesto por algo que creo que es una injusticia, pero ya por la noche voy a comer tacos, me doy un poco de tequila y se me olvida. \n",
            "Creo que no hay nada de malo con eso. Por eso mis canciones tienen de todo. Estamos en la discoteca, estamos en la playa, llorando por un amor, estamos molestos por la injusticia social porque así es. \n",
            "Sí, siempre hay diferentes sentimientos en las canciones para que puedas escucharlo y tomar de él lo que quieras. Por ejemplo, recuerdo cuando estábamos haciendo Estamos Bien, también dio una idea de lo que está pasando y lo hice para que también pudieras sentir por la Isla y Puerto Rico. En esa canción también hablo de culos y chavos (dinero) y cosas así, más trap para que la gente de la calle que también le gusta eso también y puedan sentir. Para mí podría significar una cosa, pero para otra persona significa otra cosa. Así que siempre trato de hacer eso en las canciones. Si les estoy dando un mensaje, lo haré de una manera que pueda interpretarse en diferentes maneras para que diferentes personas se puedan identificar. \n",
            "¡Sí, sin duda! Creo que el reggaetón y todos los géneros musicales son un medio para expresarse. Siempre lo han sido. La música siempre ha contado historias de cosas buenas, cosas malas, cosas peligrosas, cosas que te molestan. Así que el reggaeton es solo otro género de música que nace de la calle, del barrio. Siempre hay espacio y oportunidad para hablar un poco de todo en los discos de reggaeton. Por eso tengo canciones para la discoteca. Tengo música para todo.\n",
            "Me han preguntado eso antes…ha pasado mucho tiempo desde que tuve una pregunta como esa. Dentro de mi ignorancia no lo entendía. Dije que eso no puede ser. No podía imaginarlo. No puedo decir que sí o que no porque no lo he vivido.Tampoco he visto con mis propios ojos que sí, esta persona no se volvió más exitosa debido a su piel, no lo he visto. Sería irresponsable de mi parte decir que sí. Por ejemplo, me preguntaron si Tego Calderón, si hubiera sido más grande si no fuera negro. Pero a mis ojos, Tego Calderón es el cantante más grande de la industria. ¿Tú entiendes? No entendía cosas sobre la industria que tal vez sean ciertas. Quizás las puertas se cerraron por su piel, quizás algún promotor prefirió a un artista más blanco que él. Pero esas cosas no las sé, no las he vivido. Cuando me preguntaron dije: ‘¿Qué? Para mí Tego Calderón es el cantante más grande del género, también es uno de mis ídolos. ¿Qué quieres decir con no tan grande? ¿Quién es más grande que él?’\n",
            "Sí, claro. Para mí es importante mantener siempre el respeto por aquellos que lo merecen. Si ves a alguien por quien te sientes inspirado y admirado, dilo y dilo con respeto. No importa lo grande que crezca, incluyo personas que me han inspirado que para mejor no necesariamente estaría aquí, yo no tengo nombre pero hay artistas que yo escuchaba y los veo y los respeto por igual. No quiero olvidarme de su historia. \n",
            "Nunca me dijeron qué hacer. Me dieron la libertad de hacer lo que quisiera y supe que quería cantar “Después De La Playa”. Mucha gente pensó que interpretaría “Titi Me Pregunto” o “Moscow Mule,” pero yo sabía que quería hacer “Después De La Playa.” Pero yo quería algo más. Así que tuve la idea de hacer la primera parte de “El Apagón,” y mano, la idea surgió de forma muy espontánea y natural. En Puerto Rico en el mes de enero se celebra la fiesta de la calle San Sebastián. Es un festival puertorriqueño súper grande y tradicional donde verás personalidades retratadas por los cabezudos. Increíblemente, en toda mi vida nunca he estado en uno. Así que pensé que este año quería ir. Pensé que encontraría la manera de ponerme allí, pero no pude porque estaba aquí, así que pensé, sabes qué, traeré las fiestas de San Sebastián a los Grammy. En realidad no sabía que iba a ser el acto de apertura. Eso fue algo que se decidió en el último minuto. Creo que después de ver el programa pensaron en ponerlo como el primer acto. Y yo dije, ‘¿primero?’ Fue todo muy natural.\n",
            "Read More: Allow Bad Bunny to Teach You Puerto Rican Slang\n",
            "En realidad, cuando lo vi… no capté el mensaje. No decía ‘en español’… como que ‘non English’… bueno, el sistema no funciona. Fue una porquería, esa es la única forma en que podría decirlo. \n",
            "¡Esa línea es de Tego Calderón! Lo que sucede cuando estás creando música, especialmente a mí, es que soy el tipo de persona que cambia de humor rápidamente. Así que cuando escribí esa canción estaba molesto. Pensé: esta gente… ¿qué piensan? Eso por el momento… hay artistas que quieren hacer cosas y también ahora, mencionaron sus raíces latinas que nunca han dicho pero ahora por el momento, sí quieres hacer una canción en español. Cabrona, llevas 20 años cantando y ahora quieres hacer una canción en español? ¿No lo hiciste en tu mejor momento pero ahora quieres hacer una canción en español porque no estás apagá en tu mejor momento? Entonces cosas así las veo y en ese momento me molestó. Pero ahora ese sentimiento me ha superado. No es que me sienta así en este momento. Es bueno hacer lo que quieras. Y lo mismo para otros artistas que son gringos que nunca tendrían la oportunidad de trabajar con un artista latino o hacer una canción en español, y ahora los ves mirando la música latina porque está en la cima. Se volvió ‘cool’ ser latino. No solo están haciendo la música, están tratando de copiar el flujo de los latinos. Pero luego pienso; nuestra cultura y nuestra música se extienden por todas partes. Impacta a personas en otros lugares. Quieren probarlo y sentirlo. Entonces, ¿por qué me va a molestar eso, sí lo hacen con respeto?\n",
            "Read More: Reggaeton Is So Much More Than Party Music. This Podcast Breaks Down Its Political Roots\n",
            "Me molesta mucho. Creo que lo que más me molesta es que quieran venir, tomar posesión, ocupar un espacio, pero no quieren abrazar nada, ni ayudar. No quieren devolver. Cuando vas a un barrio nuevo siempre te van a mirar raro porque eres del otro lado. Van a sentir que les estás quitando algo, como cuando te ven usando la cancha de baloncesto y no eres de ahí, claro que te mirarán mal. Pero si esa persona abraza y aporta al barrio estoy seguro que de alguna manera te aceptará poco a poco. Esto es bueno. ¿Tú entiendes? Creo que eso es todo. El otro día estaba viendo un TikTok de una chica blanca hablando del huracán María con tanta alegría, diciendo que fue lo mejor que le pasó a Puerto Rico. Lo dijo muy contenta, y claro, sí los puertorriqueños buscamos lo positivo de las situaciones por encima de lo negativo. Pero no es lo mismo. Entonces creo que eso es lo que más me molesta, no tener empatía ni respeto por el lugar del que se van a beneficiar.\n",
            "Sí, siempre se lo hablo a mis amigos de aquí. Si estoy con alguien a quien puedo educar, lo haré. Siempre lo hago. Y no solo en las canciones o la entrevista. Lo hago en la vida real. Si estoy con alguien y escuchó algo muy ignorante sobre mi país o mi cultura, siempre trato de educarlo, como ‘No, no es así.’\n",
            "[Ríe inmediatamente] Yo creo que el gobierno le ha fallado a Puerto Rico, le ha fallado a Estados Unidos. Igualmente, Puerto Rico le ha fallado a Puerto Rico. Creo que todos los gobiernos le han fallado a su país alguna vez.\n",
            "Sí, creo que es injusto. Y es por eso que algunos artistas no lo hacen. Si no hablas de eso en tus canciones, no recibirás este tipo de preguntas. No le van a preguntar a Daddy Yankee, no le van a preguntar algo así. No sé por qué dije Daddy Yankee, lo siento Daddy Yankee. No les preguntarán algo así porque no habla de eso en las canciones. Limitaré hablar de eso porque entonces no quiero que me pregunten. Cuando estoy escribiendo mi música no estoy pensando, ‘Bueno, entonces me van a preguntar’. Estoy pensando simplemente en expresarme en ese momento. Porque cuando me preguntan puede ser difícil para mí responder porque no soy tan bueno con mis palabras cuando hablo. Pero en las canciones sí, ahí lo diré porque ahí es donde me siento cómodo, me siento inteligente, me siento capaz. En mis canciones podré expresarme plenamente como quiero la pregunta podría ser un poco injusta porque simplemente hago una canción y luego una responsabilidad tan grande cae sobre mi. Esa responsabilidad no es solo mía. Si no sacará esa canción hablando de algo nadie me preguntaría. No estaríamos haciendo una entrevista con ese tipo de pregunta. \n",
            "Sí. Porque no me importa la fama. No me importa esa presión de la que hablábamos. No me importa eso. Soy una persona. Soy un ser humano y cometo errores. Siempre he dicho que voy a vivir como quiera. Pero yo nunca me limito de hacer de una manera o actuar de una manera por lo que van a decir o pensar, no. Soy famoso y no dejó de ser humano.\n",
            "Siempre me ha gustado actuar. Donde crecí, si algo te gusta es lo único que te gusta. Es complicado tomar clases de música, piano, canto y actuación. Requiere dinero y tiempo. Cuando creces donde las condiciones no son las de la ciudad como San Juan, tienes casi todo, teatros y esas cosas. Siempre me gustó actuar, pero no más que la música. La música siempre primero. Entonces, cuando llegó la oportunidad de actuar, llegó gracias a mi fama y éxito en la música. Lo he probado y me gusta. La experiencia del Bullet Train fue súper cabrón.\n",
            "Read More: Bad Bunny Speaks Out on Black Lives Matter Protests\n",
            "Definitivamente peleando con Brad Pitt. Esa pelea fue dura porque fue física y seria. Pero los dos eran cabronas (peleas increíbles). El día con Mizz, esa pelea ese día fue el mejor día de mi vida.\n",
            "Creo que es posible que operen de otra manera. Si entendieran que somos iguales, somos humanos, que no debemos ser agresivos, ¿por qué invadir mi espacio privado? Siempre lo he dicho, que nunca le voy a negar un saludo a alguien. Nunca te voy a dejar con la mano extendida para saludarme, jamás. Si te acercas a mí como si fueras a robar, entonces sí, me voy a molestar. Alguien me pide una foto, estiro la mano y ahí la dejan porque están buscando el teléfono. ¿Por qué quieres una foto contigo? ¿Por qué soy la estatua de la libertad? Soy un humano, saludame. La foto no vale más que un saludo. Una foto no vale más que un intercambio de palabras. Eso vale más que una foto. Puedes decir que yo conocí a Bad Bunny. ¿Prefieres conocerme o hacerte una foto conmigo?\n",
            "Siempre digo que vivo en PR porque, no sé. Podría estar dos años en L.A. pero siempre diré que vivo en Puerto Rico. Ahora estoy aquí en Los Ángeles por un ratito. Me gustaría mudarme a otros lugares, a Nueva York. Pero sí, mi casa es Puerto Rico. Digo que todavía vivo en Puerto Rico porque sé que es un ratito. Solo por un rato buscando otras experiencias. Pero al final del día siempre regresaré a Puerto Rico y me quedaré para siempre.\n",
            "Asombroso, esa fue una de mis primeras experiencias actuando. Recuerdo que estaba nervioso. Creo que estaba más nervioso que con Bullet Train porque era mi primera experiencia. No quería ‘joderlo’ o dañarlo. Actuar con Gael fue genial y me trataron súper bien. Me alegro que haya sido mi primera experiencia. \n",
            "Está cabrón. Mi primer beso para una película, y fue con un hombre. Ese es el castigo que recibo por estar con tantas mujeres durante mi vida. [Comienza a reír] Si estás actuando, estás siendo alguien que no eres. Esa es la parte divertida. Entonces, cuando me preguntaron por eso, dije: ‘Sí, estoy aquí para lo que quieras’. No me sentí incómodo. Es parte de la actuación. Es parte de lo que estoy haciendo. \n",
            "Aún no hemos grabado ninguna escena. Quizá me cambien por Pedro Pascal. [Risas] \n",
            "El mejor día de mi vida. Nunca antes había sentido ese tipo de adrenalina. Yo quería explotar. Era como si volviera a ser un niño, y en la pelea, fue un abrir y cerrar de ojos. Todo sucedió rápido.\n",
            "Read More: How Puerto Ricans Are Fighting Back Against the Outsiders Using the Island as a Tax Haven\n",
            "No. Siempre he dicho que debo aprender. Hay muchas cosas que estoy perdiendo, como oportunidades, por el idioma. No me importaba [aprender] inglés. Pero ahora si, creo que me importa. Ha sido tan natural simplemente hablar y practicar, pero sin presión o con un objetivo o algo así.\n",
            "No, porque creo que es una pregunta justa. Pero nadie le pregunta a Drake cuándo va a hacer una canción en español. El día que sienta que necesito hacer una canción en inglés, lo haré porque lo siento.\n",
            "Todos los días hago ejercicio, descanso, veo televisión, escribo música, pero sin presión, no es que tenga que hacerlo, es porque me gusta.\n",
            "Para Un Verano Sin Ti, puse plantitas para que pareciera tropical. Ahora he creado un espacio que parece de los años 70, muy colorido, vintage. Colores de esa época. Estoy en esa vibra ahora mismo. Estoy comprando autos de los 70, mierda de los 70. Drogas de los 70. [Risas] \n",
            "Mucha gente me pregunta eso en la calle. Estoy como, ‘¿Se supone que debo sentir algo?’ Me presenté en Azteca, me presenté en el Yankee Stadium. He hecho función en todos los lugares. Coachella va a ser otra f-king función para mí. Sentí más presión en el Hiram Bithorn [Estadio en Puerto Rico] que en Coachella. Obviamente estoy emocionado. Quiero dar lo mejor de mí.\n",
            "Hay muchas megaestrellas que se han presentado en Coachella antes, así que no quiero competir con ninguna de ellas. Solo quiero ser yo mismo. Muchas leyendas han actuado en Coachella pero nadie como yo. Nunca ha habido un Benito actuando en Coachella. Y eso es lo bueno para mí.\n",
            "Quiero que disfruten del ‘show.’ Quiero que la gente se sienta libre como, ‘esto es Coachella, pero no es Coachella,’ estamos en el barrio, en la playa. En Coachella, nunca ha habido alguien de donde vengo. No ha ido nadie con lo que voy a llevar. Quiero que la gente no sienta presión ni responsabilidad. Vamos a disfrutar donde estamos ahora porque no sabemos a dónde vamos a estar después.\n",
            "Estuve mirando todos los folletos de Coachella desde el ‘99. Olvidé que lo estaba haciendo este año. Vi que decía mi nombre para 2023, pensé que era falso. Fue un poco impresionante. Todas las personas que han estado y ahora soy yo, pero eso no cambia quién soy como artista y como persona. Si estoy ahí es porque hago bien mi trabajo. No quiero intentar hacer algo más grande que Beyonce o Radiohead.\n",
            "¿Hay una canción con Justin Bieber? ¿Es un rumor? No, no tengo una canción con Justin Bieber. Eso es falso. Nunca vas a saber lo que voy a hacer. No te mientas a ti mismo, no vas a saber mi próxima movida.\n",
            "—Reportando en Español por Israel Meléndez Ayala\n",
            "Write to Mariah Espada at mariah.espada@time.com\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL del artículo\n",
        "url = \"https://time.com/6266396/bad-bunny-entrevista-coachella/\"\n",
        "\n",
        "# Realizar una solicitud HTTP para obtener el contenido de la página\n",
        "response = requests.get(url)\n",
        "\n",
        "# Verificar si la solicitud fue exitosa\n",
        "if response.status_code == 200:\n",
        "    # Analizar el contenido HTML de la página con BeautifulSoup\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "    # Buscar los párrafos de la página (puedes cambiar el selector según la estructura de la página)\n",
        "    article_content = soup.find_all(\"p\")\n",
        "\n",
        "    # Extraer el texto de cada párrafo\n",
        "    article_text = \"\"\n",
        "    if article_content:\n",
        "        for paragraph in article_content:\n",
        "            article_text += paragraph.get_text() + \"\\n\"\n",
        "\n",
        "        # Imprimir el texto del artículo\n",
        "        print(article_text)\n",
        "    else:\n",
        "        print(\"No se encontró el contenido del artículo.\")\n",
        "else:\n",
        "    print(\"Error al obtener la página:\", response.status_code)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Selección de pipeline para responder preguntas en español\n",
        "- Nota: Se provó un modelo multi-lenguaje pero las respuestas que entregaba, no eran óptimas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73b3294b356449de8d87a30093a4fe5d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/844 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "384a3b51c4a84334b35a5a6d3b3a7ff7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a61509f67b64712b6b95f77c613fffd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/477 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93bea2e03b314227aa17c7020cb7577f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.74M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed552fce15d44173b290b09e01928cee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Cargar un pipeline de question-answering\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"dccuchile/albert-xlarge-spanish-finetuned-qa-mlqa\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prueba preguntas y respuestas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Respuesta: Hiram Bithorn\n"
          ]
        }
      ],
      "source": [
        "context = article_text\n",
        "\n",
        "question = \"¿Donde sitino más presion Bad Bunny?\"\n",
        "\n",
        "result = qa_pipeline(question=question, context=context)\n",
        "\n",
        "print(f\"Respuesta: {result['answer']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "question = \"¿Que canción tiene con justin beiber?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Respuesta: rumor\n"
          ]
        }
      ],
      "source": [
        "result = qa_pipeline(question=question, context=context)\n",
        "\n",
        "print(f\"Respuesta: {result['answer']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Qué pasa si el articulo lo comparten en inglés y la pregunta se debe hacer en español?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: langdetect in /Users/juanpablo.cuellar/Library/Python/3.9/lib/python/site-packages (1.0.9)\n",
            "Requirement already satisfied: sentencepiece in /Users/juanpablo.cuellar/Library/Python/3.9/lib/python/site-packages (0.2.0)\n",
            "Requirement already satisfied: six in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from langdetect) (1.15.0)\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.2 is available.\n",
            "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install langdetect sentencepiece\n",
        "#from langdetect import detect"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Seleción modelo de traducción"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        }
      ],
      "source": [
        "#%pip install sentencepiece\n",
        "translator = pipeline(\"translation_en_to_es\", model=\"Helsinki-NLP/opus-mt-en-es\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- En caso de que el texto venga en inglés el pipline realiza la traducción, de lo contrario, se lee como un articulo en español"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El texto está en inglés. Traduciendo al español...\n",
            "A lo largo de febrero, Geoffrey Hinton, uno de los investigadores de IA más influyentes de los últimos 50 años, tuvo un “momento eureka lento.” Hinton, de 76 años, ha pasado su carrera tratando de construir sistemas de IA que modelen el cerebro humano, sobre todo en la academia antes de unirse a Google en 2013. Siempre había creído que el cerebro era mejor que las máquinas que él y otros estaban construyendo, y que al hacerlos más como el cerebro, mejorarían. Pero en febrero, se dio cuenta de “la inteligencia digital que tenemos ahora \n",
            "Los desarrolladores de todo el mundo están compitiendo actualmente para construir los sistemas de IA más grandes que puedan. Dada la tasa actual a la que las compañías de IA están aumentando el tamaño de los modelos, podría pasar menos de cinco años hasta que los sistemas de IA tengan 100 billones de conexiones, aproximadamente tantas como haya entre las neuronas en el cerebro humano. Alarmado, Hinton dejó su puesto como vicepresidente y compañero de ingeniería en mayo y dio una gran cantidad de entrevistas en las que exp \n",
            "Lanzó que se había ido para poder hablar libremente sobre los peligros de la IA —y sus lamentos por ayudar a traer esa tecnología a la existencia—. Se preocupa por lo que podría suceder una vez que los sistemas de IA alcancen el tamaño de los cerebros humanos— y por la perspectiva de que la humanidad sea aniquilada por la tecnología que ayudó a crear. “Esto se hará más inteligente que nosotros y se hará cargo”, dice Hinton. “Y si quieres saber lo que se siente, pregúntale a un pollo”. Nacido y criado en Inglaterra, Hinton proviene de una larga línea de \n",
            "Luminarias, con familiares incluyendo la matemática Mary Everest Boole y el lógico George Boole, cuyo trabajo es crucial para la ciencia moderna de la computación; cirujano James Hinton; y agrimensor George Everest, quien dio su nombre a la montaña. El cerebro humano siempre fascinó Hinton. Como estudiante de la Universidad de Cambridge, probó una serie de temas —fisiología, física, filosofía— antes de graduarse con un título en psicología experimental en 1970. Trabajó brevemente como carpintero antes de comenzar un doctorado en AI. \n",
            "En la Universidad de Edimburgo, el único programa de postgrado del Reino Unido sobre el tema, en 1972. En la década de 1970, la inteligencia artificial, después de no estar a la altura de su promesa de posguerra, estaba pasando por un período de atenuado entusiasmo ahora conocido como el “invierno AI”. En este campo infashionable, Hinton persiguió una idea impopular: sistemas de IA conocidos como redes neuronales, que imitaban la estructura del cerebro humano. Su asesor de tesis lo instó semanalmente a cambiar su enfoque. \n",
            "ed, “Dame otros seis meses y te demostraré que funciona”. Al terminar su doctorado, Hinton se trasladó a los EE.UU., donde había más fondos disponibles para su investigación. Publicó investigaciones pioneras, por las que fue galardonado con el Premio Turing 2018, en puestos en universidades a través de los EE.UU., antes de finalmente tomar una cátedra en ciencias de la computación en la Universidad de Toronto. Toronto se ha convertido en la base de Hinton; viaja relativamente infrecuentemente porque los problemas de espalda le impiden sitti \n",
            "ng abajo. Durante los viajes en coche se acuesta a través del asiento trasero; come arrodillado ante una mesa “como un monje en el altar”; y mientras hablaba con TIME se balanceó suavemente delante de una cámara de altura. En 2012, Hinton y dos de sus estudiantes graduados, Alex Krizhevsky e Ilya Sutskever, ahora científico jefe de OpenAI, entraron en ImageNet, una vez al año en la que los investigadores compitieron para construir los sistemas de IA de reconocimiento de imágenes más precisos. \n",
            "La persistencia de Hinton había dado sus frutos. Él y sus dos estudiantes comenzaron a recibir ofertas lucrativas de las grandes compañías de tecnología. Ellos establecieron una compañía fantasma llamada DNN-investigación para subastar su experiencia, y cuatro empresas de tecnología —Google, Microsoft, Baidu, y DeepMind— ofrecen decenas de millones para la compañía. Después de una semana, Hinton eligió Google sobre el postor final, Baidu. En 2013, se unió a Google Brain, el equipo de aprendizaje automático de vanguardia que dejó en mayo. Hinton ha sido instrumental en el desarrollo \n",
            "nt y la popularización de las redes neuronales, el paradigma dominante del desarrollo de la IA que ha permitido ingerir y procesar enormes cantidades de datos, lo que ha llevado a avances en el reconocimiento de imágenes, comprensión del lenguaje y autos autoconductores. Su trabajo potencialmente ha acelerado el futuro que teme, en el que la IA se vuelve sobrehumana con resultados desastrosos para los humanos. En una entrevista con el New York Times, Hinton dijo: “Me consuela con la excusa normal: si no lo hubiera hecho, alguien más lo habría hecho”. \n",
            "s no sabe cómo evitar que los sistemas de IA sobrehumanos se hagan cargo. Si hay alguna esperanza, dice, yace en la próxima generación, señalando que se siente demasiado viejo para seguir contribuyendo a la investigación. Muchos científicos cambian a la política de trabajo más tarde en sus carreras, pero rechazó la oferta de Google de asumir un papel en la empresa. “Nunca he sido muy bueno en o interesado en cuestiones de política,” le dice a TIME. “Soy un científico.” En cambio, Hinton ha pasado los últimos meses haciendo sonar la alarma, puede explicar la tecnología \n",
            "También ha hablado con los responsables de la formulación de políticas, incluidos funcionarios de la oficina del Primer Ministro del Reino Unido, el primer ministro canadiense Justin Trudeau, el vicepresidente ejecutivo de la Comisión Europea Margrethe Vestager, y los senadores estadounidenses Bernie Sanders y Jon Ossoff. Mientras que en un nivel teórico él ahora capta los riesgos de AI, Hinton dice que sus emociones todavía no han alcanzado. \n",
            "que vamos a ser reemplazados como el ápice de la inteligencia es muy difícil de conseguir su cabeza alrededor.” Pero por ahora, él toma sus señales de otro pariente: su primo Joan Hinton era una de las únicas mujeres científicas que trabajan en el Proyecto Manhattan. Después de que las armas nucleares que ella ayudó a crear fueron abandonadas en Hiroshima y Nagasaki, ella se convirtió en una activista por la paz. En 1948 se mudó a China, y pasó la mayor parte de su vida trabajando en granjas lecheras como un ardiente maoísta. \n",
            "Los lans son menos estridentes pero también bucólicos: tiene la intención de redescubrir la carpintería y dar largos paseos. Escribir a Will Henshall en will.henshall@time.com.\n"
          ]
        }
      ],
      "source": [
        "# URL del artículo\n",
        "url = \"https://time.com/collection/time100-ai/6309026/geoffrey-hinton/\"\n",
        "\n",
        "# Realizar una solicitud HTTP para obtener el contenido de la página\n",
        "response = requests.get(url)\n",
        "\n",
        "# Verificar si la solicitud fue exitosa\n",
        "if response.status_code == 200:\n",
        "    # Analizar el contenido HTML de la página con BeautifulSoup\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "    # Buscar los párrafos de la página\n",
        "    article_content = soup.find_all(\"p\")\n",
        "\n",
        "    # Extraer el texto de cada párrafo\n",
        "    article_text = \"\"\n",
        "    if article_content:\n",
        "        for paragraph in article_content:\n",
        "            article_text += paragraph.get_text() + \"\\n\"\n",
        "\n",
        "        # Detectar el idioma del texto\n",
        "        detected_language = detect(article_text)\n",
        "\n",
        "        # Si el idioma detectado es inglés, traducir al español\n",
        "        if detected_language == 'en':\n",
        "            print(\"El texto está en inglés. Traduciendo al español...\")\n",
        "            \n",
        "            # Dividir el texto en fragmentos más pequeños\n",
        "            max_length = 512\n",
        "            chunks = [article_text[i:i+max_length] for i in range(0, len(article_text), max_length)]\n",
        "            \n",
        "\n",
        "            # Traducir cada fragmento y concatenar los resultados\n",
        "            # se hace la separación ya que el length máximo de la traducción es de 512 y el texto en muchos casos es más largo\n",
        "            translated_text = \"\"\n",
        "            for chunk in chunks:\n",
        "                translated_chunk = translator(chunk, max_length=max_length)[0]['translation_text']\n",
        "                translated_text += translated_chunk + \" \" + \"\\n\"\n",
        "            \n",
        "            article_text = translated_text.strip()\n",
        "        \n",
        "        # Imprimir el texto (ya traducido si era necesario)\n",
        "        print(article_text)\n",
        "    else:\n",
        "        print(\"No se encontró el contenido del artículo.\")\n",
        "else:\n",
        "    print(\"Error al obtener la página:\", response.status_code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd9e2cd15c5b4b8880acd35030f25fdf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/845 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a71ac6f13da548578d039975c52ad348",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/219M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a1d4a0a054241e8bce2132e48d3f6c6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/478 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1179b36288c04fb1ac6b0d017fdc9a42",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.74M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da210cbf35c949e089f3f3f8acd018da",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        }
      ],
      "source": [
        "qa_pipeline = pipeline(\"question-answering\", model=\"dccuchile/albert-xlarge-spanish-finetuned-qa-mlqa\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Respuesta: uno de los investigadores de IA más influyentes de los últimos 50 años,\n"
          ]
        }
      ],
      "source": [
        "context = article_text\n",
        "\n",
        "question = \"¿Quién es Geoffrey Hinton?\"\n",
        "\n",
        "result = qa_pipeline(question=question, context=context)\n",
        "\n",
        "print(f\"Respuesta: {result['answer']}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPQDd+VMwtpkPdp8wqHP1S4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
